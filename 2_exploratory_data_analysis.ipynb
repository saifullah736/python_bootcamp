{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Optimiser: Exploratory Data Analysis (EDA)\n",
    "\n",
    "## Project Overview\n",
    "Following the data integrity check, this notebook performs comprehensive exploratory data analysis to understand the job posting landscape for data roles.\n",
    "\n",
    "### Key Questions to Explore:\n",
    "1. What is the distribution of data roles in the market?\n",
    "2. How do salaries vary across roles and experience levels?\n",
    "3. Which locations have the highest demand for data professionals?\n",
    "4. What are the most in-demand skills for each role?\n",
    "5. How do company sizes affect job requirements and compensation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Load and clean the dataset\n",
    "df = pd.read_csv('job_postings_dataset.csv')\n",
    "\n",
    "# Basic data cleaning\n",
    "# Standardize date format\n",
    "df['posting_date_clean'] = pd.to_datetime(df['posting_date'])\n",
    "\n",
    "# Remove rows with missing critical information\n",
    "df_clean = df.dropna(subset=['job_title', 'company', 'location']).copy()\n",
    "\n",
    "print(f\"Original dataset: {len(df)} records\")\n",
    "print(f\"Cleaned dataset: {len(df_clean)} records\")\n",
    "print(f\"Records removed: {len(df) - len(df_clean)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Job Market Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Job title distribution\n",
    "job_distribution = df_clean['job_title'].value_counts()\n",
    "print(\"=== JOB MARKET OVERVIEW ===\")\n",
    "print(\"Job Title Distribution:\")\n",
    "for job, count in job_distribution.items():\n",
    "    percentage = (count / len(df_clean)) * 100\n",
    "    print(f\"{job}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "# Visualize job distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Bar chart\n",
    "job_distribution.plot(kind='bar', ax=ax1, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "ax1.set_title('Job Postings by Role', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Job Title')\n",
    "ax1.set_ylabel('Number of Postings')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Pie chart\n",
    "ax2.pie(job_distribution.values, labels=job_distribution.index, autopct='%1.1f%%',\n",
    "        colors=['#FF6B6B', '#4ECDC4', '#45B7D1'], startangle=90)\n",
    "ax2.set_title('Job Market Share by Role', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Salary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salary analysis by job title\n",
    "print(\"=== SALARY ANALYSIS ===\")\n",
    "\n",
    "# Remove outliers for better visualization\n",
    "salary_data = df_clean[df_clean['salary'].notna()]\n",
    "Q1 = salary_data['salary'].quantile(0.25)\n",
    "Q3 = salary_data['salary'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "salary_clean = salary_data[(salary_data['salary'] >= Q1 - 1.5*IQR) & \n",
    "                          (salary_data['salary'] <= Q3 + 1.5*IQR)]\n",
    "\n",
    "# Salary statistics by job title\n",
    "salary_stats = salary_clean.groupby('job_title')['salary'].agg([\n",
    "    'count', 'mean', 'median', 'std', 'min', 'max'\n",
    "]).round(0)\n",
    "\n",
    "print(\"Salary Statistics by Job Title:\")\n",
    "print(salary_stats)\n",
    "\n",
    "# Visualize salary distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Box plot by job title\n",
    "sns.boxplot(data=salary_clean, x='job_title', y='salary', ax=axes[0,0])\n",
    "axes[0,0].set_title('Salary Distribution by Job Title', fontweight='bold')\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "axes[0,0].yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1000:.0f}K'))\n",
    "\n",
    "# Box plot by experience level\n",
    "sns.boxplot(data=salary_clean, x='experience_level', y='salary', ax=axes[0,1])\n",
    "axes[0,1].set_title('Salary Distribution by Experience Level', fontweight='bold')\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "axes[0,1].yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1000:.0f}K'))\n",
    "\n",
    "# Histogram of all salaries\n",
    "salary_clean['salary'].hist(bins=30, ax=axes[1,0], alpha=0.7, color='skyblue')\n",
    "axes[1,0].set_title('Overall Salary Distribution', fontweight='bold')\n",
    "axes[1,0].set_xlabel('Salary ($)')\n",
    "axes[1,0].set_ylabel('Frequency')\n",
    "axes[1,0].xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1000:.0f}K'))\n",
    "\n",
    "# Average salary by job title\n",
    "avg_salary = salary_clean.groupby('job_title')['salary'].mean().sort_values(ascending=True)\n",
    "avg_salary.plot(kind='barh', ax=axes[1,1], color='lightcoral')\n",
    "axes[1,1].set_title('Average Salary by Job Title', fontweight='bold')\n",
    "axes[1,1].xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1000:.0f}K'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Geographic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geographic distribution analysis\n",
    "print(\"=== GEOGRAPHIC ANALYSIS ===\")\n",
    "\n",
    "# Top locations by job count\n",
    "location_counts = df_clean['location'].value_counts().head(10)\n",
    "print(\"Top 10 Locations by Job Count:\")\n",
    "for location, count in location_counts.items():\n",
    "    percentage = (count / len(df_clean)) * 100\n",
    "    print(f\"{location}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "# Average salary by location (top 10 locations)\n",
    "top_locations = location_counts.index[:10]\n",
    "salary_by_location = salary_clean[salary_clean['location'].isin(top_locations)].groupby('location')['salary'].mean().sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nAverage Salary by Top Locations:\")\n",
    "for location, avg_salary in salary_by_location.items():\n",
    "    print(f\"{location}: ${avg_salary:,.0f}\")\n",
    "\n",
    "# Visualize geographic data\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 12))\n",
    "\n",
    "# Job count by location\n",
    "location_counts.plot(kind='barh', ax=ax1, color='steelblue')\n",
    "ax1.set_title('Top 10 Locations by Job Count', fontweight='bold')\n",
    "ax1.set_xlabel('Number of Job Postings')\n",
    "\n",
    "# Average salary by location\n",
    "salary_by_location.plot(kind='barh', ax=ax2, color='orange')\n",
    "ax2.set_title('Average Salary by Location', fontweight='bold')\n",
    "ax2.set_xlabel('Average Salary ($)')\n",
    "ax2.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1000:.0f}K'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Job distribution by location and role\n",
    "location_role_crosstab = pd.crosstab(df_clean['location'], df_clean['job_title'])\n",
    "top_10_locations = df_clean['location'].value_counts().head(10).index\n",
    "location_role_top = location_role_crosstab.loc[top_10_locations]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "location_role_top.plot(kind='bar', stacked=True, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "plt.title('Job Distribution by Location and Role (Top 10 Locations)', fontweight='bold')\n",
    "plt.xlabel('Location')\n",
    "plt.ylabel('Number of Job Postings')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(title='Job Title')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Skills Demand Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skills analysis\n",
    "print(\"=== SKILLS DEMAND ANALYSIS ===\")\n",
    "\n",
    "# Function to extract skills for each role\n",
    "def get_skills_by_role(df, role):\n",
    "    role_data = df[df['job_title'] == role]\n",
    "    all_skills = []\n",
    "    for skills_str in role_data['required_skills'].dropna():\n",
    "        skills_list = [skill.strip() for skill in skills_str.split(',')]\n",
    "        all_skills.extend(skills_list)\n",
    "    return Counter(all_skills)\n",
    "\n",
    "# Get top skills for each role\n",
    "roles = df_clean['job_title'].unique()\n",
    "role_skills = {}\n",
    "\n",
    "for role in roles:\n",
    "    skills_counter = get_skills_by_role(df_clean, role)\n",
    "    role_skills[role] = skills_counter.most_common(10)\n",
    "    \n",
    "    print(f\"\\nTop 10 Skills for {role}:\")\n",
    "    for skill, count in skills_counter.most_common(10):\n",
    "        percentage = (count / len(df_clean[df_clean['job_title'] == role])) * 100\n",
    "        print(f\"  {skill}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "# Visualize skills by role\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for i, role in enumerate(roles):\n",
    "    skills_data = dict(role_skills[role])\n",
    "    skills_df = pd.DataFrame(list(skills_data.items()), columns=['Skill', 'Count'])\n",
    "    \n",
    "    skills_df.plot(x='Skill', y='Count', kind='bar', ax=axes[i], \n",
    "                   color=['#FF6B6B', '#4ECDC4', '#45B7D1'][i], legend=False)\n",
    "    axes[i].set_title(f'Top Skills for {role}', fontweight='bold')\n",
    "    axes[i].set_xlabel('Skills')\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Overall most demanded skills\n",
    "all_skills = []\n",
    "for skills_str in df_clean['required_skills'].dropna():\n",
    "    skills_list = [skill.strip() for skill in skills_str.split(',')]\n",
    "    all_skills.extend(skills_list)\n",
    "\n",
    "overall_skills = Counter(all_skills).most_common(15)\n",
    "\n",
    "print(\"\\n=== OVERALL TOP 15 MOST DEMANDED SKILLS ===\")\n",
    "for skill, count in overall_skills:\n",
    "    percentage = (count / len(df_clean)) * 100\n",
    "    print(f\"{skill}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "# Create overall skills chart\n",
    "overall_skills_df = pd.DataFrame(overall_skills, columns=['Skill', 'Count'])\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(overall_skills_df['Skill'], overall_skills_df['Count'], color='lightgreen')\n",
    "plt.title('Top 15 Most Demanded Skills (All Roles)', fontweight='bold', fontsize=16)\n",
    "plt.xlabel('Frequency')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Company and Experience Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Company size analysis\n",
    "print(\"=== COMPANY SIZE ANALYSIS ===\")\n",
    "\n",
    "# Distribution by company size\n",
    "company_size_dist = df_clean['company_size'].value_counts()\n",
    "print(\"Job Distribution by Company Size:\")\n",
    "for size, count in company_size_dist.items():\n",
    "    percentage = (count / len(df_clean)) * 100\n",
    "    print(f\"{size}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "# Average salary by company size\n",
    "salary_by_company_size = salary_clean.groupby('company_size')['salary'].agg(['mean', 'median', 'count']).round(0)\n",
    "print(\"\\nSalary Statistics by Company Size:\")\n",
    "print(salary_by_company_size)\n",
    "\n",
    "# Experience level analysis\n",
    "print(\"\\n=== EXPERIENCE LEVEL ANALYSIS ===\")\n",
    "exp_level_dist = df_clean['experience_level'].value_counts()\n",
    "print(\"Job Distribution by Experience Level:\")\n",
    "for level, count in exp_level_dist.items():\n",
    "    percentage = (count / len(df_clean)) * 100\n",
    "    print(f\"{level}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "# Visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Company size distribution\n",
    "company_size_dist.plot(kind='pie', ax=axes[0,0], autopct='%1.1f%%')\n",
    "axes[0,0].set_title('Job Distribution by Company Size', fontweight='bold')\n",
    "axes[0,0].set_ylabel('')\n",
    "\n",
    "# Experience level distribution\n",
    "exp_level_dist.plot(kind='pie', ax=axes[0,1], autopct='%1.1f%%')\n",
    "axes[0,1].set_title('Job Distribution by Experience Level', fontweight='bold')\n",
    "axes[0,1].set_ylabel('')\n",
    "\n",
    "# Salary by company size\n",
    "salary_by_company_size['mean'].plot(kind='bar', ax=axes[1,0], color='coral')\n",
    "axes[1,0].set_title('Average Salary by Company Size', fontweight='bold')\n",
    "axes[1,0].set_ylabel('Average Salary ($)')\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "axes[1,0].yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1000:.0f}K'))\n",
    "\n",
    "# Work arrangement distribution\n",
    "work_arrangement_dist = df_clean['work_arrangement'].value_counts()\n",
    "work_arrangement_dist.plot(kind='bar', ax=axes[1,1], color='lightblue')\n",
    "axes[1,1].set_title('Job Distribution by Work Arrangement', fontweight='bold')\n",
    "axes[1,1].set_ylabel('Number of Jobs')\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation analysis\n",
    "print(\"=== CORRELATION ANALYSIS ===\")\n",
    "\n",
    "# Create numerical encodings for categorical variables\n",
    "analysis_df = salary_clean.copy()\n",
    "\n",
    "# Encode job titles\n",
    "job_title_map = {'Data Analyst': 1, 'Data Scientist': 2, 'Data Engineer': 3}\n",
    "analysis_df['job_title_encoded'] = analysis_df['job_title'].map(job_title_map)\n",
    "\n",
    "# Encode experience levels\n",
    "exp_level_map = {\n",
    "    'Entry Level (0-2 years)': 1,\n",
    "    'Mid Level (3-5 years)': 2, \n",
    "    'Senior Level (6-10 years)': 3,\n",
    "    'Lead Level (10+ years)': 4\n",
    "}\n",
    "analysis_df['experience_encoded'] = analysis_df['experience_level'].map(exp_level_map)\n",
    "\n",
    "# Encode company sizes\n",
    "company_size_map = {\n",
    "    'Startup (1-50)': 1,\n",
    "    'Small (51-200)': 2,\n",
    "    'Medium (201-1000)': 3,\n",
    "    'Large (1001+)': 4\n",
    "}\n",
    "analysis_df['company_size_encoded'] = analysis_df['company_size'].map(company_size_map)\n",
    "\n",
    "# Calculate number of skills\n",
    "analysis_df['num_skills'] = analysis_df['required_skills'].apply(\n",
    "    lambda x: len(x.split(', ')) if pd.notna(x) else 0\n",
    ")\n",
    "\n",
    "# Select numerical columns for correlation\n",
    "correlation_columns = ['salary', 'job_title_encoded', 'experience_encoded', \n",
    "                      'company_size_encoded', 'num_skills']\n",
    "correlation_matrix = analysis_df[correlation_columns].corr()\n",
    "\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation_matrix.round(3))\n",
    "\n",
    "# Visualize correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, fmt='.3f', cbar_kws={\"shrink\": .8})\n",
    "plt.title('Correlation Matrix: Job Characteristics vs Salary', fontweight='bold', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Key insights from correlations\n",
    "print(\"\\n=== KEY CORRELATION INSIGHTS ===\")\n",
    "salary_correlations = correlation_matrix['salary'].sort_values(ascending=False)\n",
    "for var, corr in salary_correlations.items():\n",
    "    if var != 'salary':\n",
    "        strength = \"Strong\" if abs(corr) > 0.5 else \"Moderate\" if abs(corr) > 0.3 else \"Weak\"\n",
    "        direction = \"positive\" if corr > 0 else \"negative\"\n",
    "        print(f\"{var}: {corr:.3f} ({strength} {direction} correlation with salary)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Time-Based Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-based analysis\n",
    "print(\"=== TIME-BASED ANALYSIS ===\")\n",
    "\n",
    "# Job postings by month\n",
    "df_clean['posting_month'] = df_clean['posting_date_clean'].dt.to_period('M')\n",
    "monthly_postings = df_clean.groupby('posting_month').size()\n",
    "\n",
    "print(\"Job Postings by Month:\")\n",
    "for month, count in monthly_postings.items():\n",
    "    print(f\"{month}: {count} jobs\")\n",
    "\n",
    "# Job postings by role over time\n",
    "monthly_by_role = df_clean.groupby(['posting_month', 'job_title']).size().unstack(fill_value=0)\n",
    "\n",
    "# Visualize time trends\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Total monthly postings\n",
    "monthly_postings.plot(kind='line', marker='o', ax=ax1, linewidth=2, markersize=6)\n",
    "ax1.set_title('Job Postings Over Time (Total)', fontweight='bold')\n",
    "ax1.set_xlabel('Month')\n",
    "ax1.set_ylabel('Number of Job Postings')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Monthly postings by role\n",
    "monthly_by_role.plot(kind='line', marker='o', ax=ax2, linewidth=2, markersize=6)\n",
    "ax2.set_title('Job Postings Over Time by Role', fontweight='bold')\n",
    "ax2.set_xlabel('Month')\n",
    "ax2.set_ylabel('Number of Job Postings')\n",
    "ax2.legend(title='Job Title')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Seasonal patterns\n",
    "df_clean['posting_quarter'] = df_clean['posting_date_clean'].dt.quarter\n",
    "quarterly_postings = df_clean.groupby('posting_quarter').size()\n",
    "\n",
    "print(\"\\nJob Postings by Quarter:\")\n",
    "for quarter, count in quarterly_postings.items():\n",
    "    print(f\"Q{quarter}: {count} jobs\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "quarterly_postings.plot(kind='bar', color='skyblue')\n",
    "plt.title('Job Postings by Quarter', fontweight='bold')\n",
    "plt.xlabel('Quarter')\n",
    "plt.ylabel('Number of Job Postings')\n",
    "plt.xticks([0, 1, 2, 3], ['Q1', 'Q2', 'Q3', 'Q4'], rotation=0)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. EDA Summary and Key Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive EDA summary\n",
    "print(\"=== EXPLORATORY DATA ANALYSIS SUMMARY ===\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Market overview insights\n",
    "print(\"🏢 MARKET OVERVIEW INSIGHTS\")\n",
    "job_dist = df_clean['job_title'].value_counts(normalize=True) * 100\n",
    "dominant_role = job_dist.index[0]\n",
    "print(f\"   • {dominant_role} roles dominate the market ({job_dist.iloc[0]:.1f}% of postings)\")\n",
    "print(f\"   • Total job postings analyzed: {len(df_clean):,}\")\n",
    "print(f\"   • Geographic spread: {df_clean['location'].nunique()} unique locations\")\n",
    "\n",
    "# Salary insights\n",
    "print(f\"\\n💰 SALARY INSIGHTS\")\n",
    "salary_by_role = salary_clean.groupby('job_title')['salary'].mean()\n",
    "highest_paid_role = salary_by_role.idxmax()\n",
    "lowest_paid_role = salary_by_role.idxmin()\n",
    "print(f\"   • Highest average salary: {highest_paid_role} (${salary_by_role.max():,.0f})\")\n",
    "print(f\"   • Lowest average salary: {lowest_paid_role} (${salary_by_role.min():,.0f})\")\n",
    "print(f\"   • Overall salary range: ${salary_clean['salary'].min():,.0f} - ${salary_clean['salary'].max():,.0f}\")\n",
    "print(f\"   • Median salary across all roles: ${salary_clean['salary'].median():,.0f}\")\n",
    "\n",
    "# Skills insights\n",
    "print(f\"\\n🔧 SKILLS INSIGHTS\")\n",
    "all_skills_counter = Counter(all_skills)\n",
    "top_skill = all_skills_counter.most_common(1)[0]\n",
    "print(f\"   • Most in-demand skill: {top_skill[0]} (required in {top_skill[1]} jobs)\")\n",
    "avg_skills = df_clean['required_skills'].apply(lambda x: len(x.split(', ')) if pd.notna(x) else 0).mean()\n",
    "print(f\"   • Average skills per job: {avg_skills:.1f}\")\n",
    "print(f\"   • Total unique skills identified: {len(all_skills_counter)}\")\n",
    "\n",
    "# Geographic insights\n",
    "print(f\"\\n🌍 GEOGRAPHIC INSIGHTS\")\n",
    "top_location = df_clean['location'].value_counts().index[0]\n",
    "top_location_count = df_clean['location'].value_counts().iloc[0]\n",
    "top_location_pct = (top_location_count / len(df_clean)) * 100\n",
    "print(f\"   • Top job market: {top_location} ({top_location_count} jobs, {top_location_pct:.1f}%)\")\n",
    "if len(salary_by_location) > 0:\n",
    "    highest_salary_location = salary_by_location.idxmax()\n",
    "    print(f\"   • Highest paying location: {highest_salary_location} (${salary_by_location.max():,.0f} avg)\")\n",
    "\n",
    "# Company insights\n",
    "print(f\"\\n🏭 COMPANY INSIGHTS\")\n",
    "company_dist = df_clean['company_size'].value_counts(normalize=True) * 100\n",
    "dominant_company_size = company_dist.index[0]\n",
    "print(f\"   • Most common company size: {dominant_company_size} ({company_dist.iloc[0]:.1f}% of jobs)\")\n",
    "work_dist = df_clean['work_arrangement'].value_counts(normalize=True) * 100\n",
    "dominant_work = work_dist.index[0]\n",
    "print(f\"   • Most common work arrangement: {dominant_work} ({work_dist.iloc[0]:.1f}% of jobs)\")\n",
    "\n",
    "# Experience insights\n",
    "print(f\"\\n📊 EXPERIENCE INSIGHTS\")\n",
    "exp_dist = df_clean['experience_level'].value_counts(normalize=True) * 100\n",
    "dominant_exp = exp_dist.index[0]\n",
    "print(f\"   • Most common experience requirement: {dominant_exp} ({exp_dist.iloc[0]:.1f}% of jobs)\")\n",
    "\n",
    "# Correlation insights\n",
    "print(f\"\\n🔗 KEY CORRELATIONS\")\n",
    "if 'experience_encoded' in correlation_matrix.columns:\n",
    "    exp_salary_corr = correlation_matrix.loc['salary', 'experience_encoded']\n",
    "    print(f\"   • Experience level vs Salary correlation: {exp_salary_corr:.3f}\")\n",
    "if 'num_skills' in correlation_matrix.columns:\n",
    "    skills_salary_corr = correlation_matrix.loc['salary', 'num_skills']\n",
    "    print(f\"   • Number of skills vs Salary correlation: {skills_salary_corr:.3f}\")\n",
    "\n",
    "print(f\"\\n✅ EDA COMPLETE - Ready for Business Question Investigation\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Power BI Translation Notes\n",
    "\n",
    "### For Power BI Implementation:\n",
    "\n",
    "**Key Visualizations to Create in Power BI:**\n",
    "1. **Job Market Overview Dashboard**\n",
    "   - Pie chart for job title distribution\n",
    "   - Bar chart for geographic distribution\n",
    "   - Card visuals for key metrics (total jobs, avg salary, etc.)\n",
    "\n",
    "2. **Salary Analysis Dashboard**\n",
    "   - Box plots using custom visuals for salary distributions\n",
    "   - Scatter plot for salary vs experience correlation\n",
    "   - Table with salary statistics by role\n",
    "\n",
    "3. **Skills Demand Dashboard**\n",
    "   - Horizontal bar charts for top skills by role\n",
    "   - Word cloud visual for overall skills\n",
    "   - Matrix visual showing skills by job title\n",
    "\n",
    "**DAX Measures to Create:**\n",
    "- `Average Salary = AVERAGE(JobData[salary])`\n",
    "- `Job Count = COUNTROWS(JobData)`\n",
    "- `Skills Count = LEN(JobData[required_skills]) - LEN(SUBSTITUTE(JobData[required_skills], \",\", \"\")) + 1`\n",
    "- `Salary by Experience = CALCULATE(AVERAGE(JobData[salary]), FILTER(JobData, JobData[experience_level] = \"Selected Level\"))`\n",
    "\n",
    "**Power Query Transformations:**\n",
    "- Split skills column by delimiter\n",
    "- Create calculated columns for experience level ranking\n",
    "- Extract state/city from location field\n",
    "- Create salary ranges/buckets for better visualization\n",
    "\n",
    "**Next Steps:**\n",
    "Proceed to Business Question Investigation to focus on specific insights for Data Optimiser's recruitment strategy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}